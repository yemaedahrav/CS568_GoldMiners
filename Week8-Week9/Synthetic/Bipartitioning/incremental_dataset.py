# -*- coding: utf-8 -*-
"""Incremental Dataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B5Ub94pVv7PvK0Co0ej3fuRqJQuufQe6
"""

# import os
# def restart_runtime():
#   os.kill(os.getpid(), 9)
# restart_runtime()

import numpy as np
import random
import sys

# np.set_printoptions(threshold=sys.maxsize)

## Hyper Parameters

w = 200
d = 200
n_cluster = 2
p_cluster = 0.1
p_not_cluster = 0.06
ew_cluster = 0.3
ew_noncluster = 0.2

## Cluster label generations
wlabel = np.zeros(shape=(w),dtype = np.int8)
dlabel = np.zeros(shape=(d),dtype = np.int8)

for i in range(w):
  wlabel[i] = i%n_cluster
for i in range(d):
  dlabel[i] = i%n_cluster

## Cluster generations
wclusters = [[] for i in range(n_cluster)]
dclusters = [[] for i in range(n_cluster)]

for i in range(w):
  wclusters[wlabel[i]].append(i)
for j in range(d):
  dclusters[dlabel[j]].append(j)

print(wclusters)
print(dclusters)

print(wlabel)
print(dlabel)



## Word by Document Matrix

adj = np.zeros(shape = (w,d))


## Functions for datasets

def edgeweight(m):
  return random.uniform(m-0.1,m+0.1)

def gen_cluster(x):
  for i in wclusters[x]:
    for j in dclusters[x]:
      toss = np.random.binomial(1,p_cluster)
      if(toss == 1):
        adj[i][j] = edgeweight(ew_cluster)

def gen_noncluster(x,y):
  for i in wclusters[x]:
    for j in dclusters[y]:
      toss = np.random.binomial(1,p_not_cluster)
      if(toss == 1):
        adj[i][j] = edgeweight(ew_noncluster)
  for i in wclusters[y]:
    for j in dclusters[x]:
      toss = np.random.binomial(1,p_not_cluster)
      if(toss == 1):
        adj[i][j] = edgeweight(ew_noncluster)

## Generating the dataset

for i in range(n_cluster):
  gen_cluster(i)

for i in range(n_cluster):
  for j in range(i+1,n_cluster):
    gen_noncluster(i,j)

print(adj)

## Handling of matrices with zero row or zero coolumn
def is_not_zero(a):
  threshold = 0.00001
  if(abs(a) > threshold):
    return True
  else:
    return False


def make_non_zero(r,c):
  for i in range(r):
    ctr = 0
    for j in range(c):
      if(is_not_zero(adj[i][j])):
        ctr += 1
        break;
    if(ctr == 0):
      adj[i][(i+1)%c] = edgeweight(0.5)
  for i in range(c):
    ctr = 0
    for j in range(r):
      if(is_not_zero(adj[i][j])):
        ctr += 1
        break;
    if(ctr == 0):
      adj[(i+1)%r][i] = edgeweight(0.5)


def check_zero(r,c):
  for i in range(r):
    ctr = 0
    for j in range(c):
      if(adj[i][j] > 0):
        ctr+=1
    if(ctr == 0):
      return True
  
  for j in range(c):
    ctr = 0
    for i in range(r):
      if(adj[i][j] > 0):
        ctr += 1
    if(ctr == 0):
      return True
  return False
      

def generate_input_files(r,c,ind):
  make_non_zero(r,c)
  input = "/content/input" + str(ind) + ".in"
  labels = "/content/labels" + str(ind) + ".in"
  f = open(input,"w")
  f.write("{} {} {}\n".format(r,c,n_cluster))
  for i in range(r):
    for j in range(c):
      if(adj[i][j]>0):
        f.write("{} {} {:.2f}\n".format(i,j,adj[i][j]))
  f.close()
  f = open(labels,"w")
  for i in wlabel:
    f.write("{} ".format(i))
  for i in dlabel:
    f.write("{} ".format(i))
  f.close()

def num_of_edges(l,r):
  ctr = 0
  for i in range(w):
    for j in range(l,r):
      if(is_not_zero(adj[i][j])):
        ctr = ctr + 1
  return ctr

def create_incremental_dataset(initial, n_batches,ind):
  make_non_zero(w,initial)
  batch_size = (d-initial)//n_batches
  print("batch_size = " + str(batch_size))
  input = "/content/input" + str(ind) + ".in"
  labels = "/content/labels" + str(ind) + ".in"
  f = open(input,"w")

  f.write("{} {} {} {}\n".format(w,initial,2,num_of_edges(0,initial))) 
  print("{} {} {} {}\n".format(w,initial,2,num_of_edges(0,initial)))  
  for i in range(w):
    for j in range(initial):
      if(is_not_zero(adj[i][j])):
        f.write("{} {} {}\n".format(i,j,adj[i][j]))
        
  for b_num in range(n_batches):
    l = initial+b_num*batch_size
    r = initial+(b_num+1)*batch_size
    print(str(l) + str(" ") + str(r))
    f.write("{} {} {}\n".format(batch_size, 0, num_of_edges(l,r)))
    print("{} {} {}\n".format(batch_size, 0, num_of_edges(l,r)))
    for doc_num in range(l,r):
      f.write("{} {}\n".format(doc_num, 1))
    for i in range(w):
      for j in range(l,r):
        if(is_not_zero(adj[i][j])):
          f.write("{} {} {}\n".format(i,j,adj[i][j]))
  f.close()
  
  f = open(labels,"w")
  for i in dlabel:
    f.write("{} ".format(i))
  f.close()

create_incremental_dataset(80,3,"")

print(adj[0][4])

inp = open("input.in","r")
x = inp.readlines()
print(len(x))

1637 + 608 + 663 + 610 + 120

##Generation of input

# start = 100
# for i in range(5):
#   generate_input_files(start+i*9,start+i*9,i)


## Generating the dataset of size MedCran

# # Uncomment to download files
 
# !zip -r /content/synthetic_dataset.zip /content/ 
# from google.colab import files
# files.download("synthetic_dataset.zip")